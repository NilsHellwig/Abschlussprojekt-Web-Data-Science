# Notebook: Collect Tweets Mentioning Flights

This notebook is used to collect tweets in which flights (respectively their flight number) are mentioned. Since the current Twitter API v2 is very expensive, I have been looking for a tool that allows me to collect tweets on a large scale without an API key from Twitter and without major limitations. In the process, I came across Snscrape.

Snscrape: https://github.com/JustAnotherArchivist/snscrape 

Snscrape is a Python-based CLI that allows, among other things, unlimited (no maximum amount of requests, no time limit) crawling of tweets using Twitter search. The usual Twitter search operators can be used. See here: https://developer.twitter.com/en/docs/twitter-api/v1/rules-and-filtering/search-operators.

## Load Packages

```{r}
library(reticulate)
library(jsonlite)
library(dplyr)
library(tidyr)
```

## Settings

### Install Snscrape

Due to the fact that this is a Python-based tool, it is necessary to install it using Python. I will just select my conda environment.

```{r}
use_condaenv("/opt/homebrew/Caskroom/miniforge/base/envs/tensorflow_m1")
```

I have personally experienced that the version of snscrape installed via `pip install snscrpape` is not the latest one available in the official GitHub repo. The latest version that could be installed via pip as of 21 June 2023 resulted in a "missing token" error, whereas the latest version on GitHub worked without problems.

```{r}
system("pip install git+https://github.com/JustAnotherArchivist/snscrape.git", intern=TRUE)
```

## Load Dataset

The flight numbers that occur in the main data set are to be considered, whereby only tweets from the period for which I have also collected tweets are to be collected.

```{r}
departure_data <- read.csv("../datasets/departure_dataset.csv")
```

```{r}
lowest_date <- format(min(as.Date(departure_data$departure_scheduled_datetime_local)), "%Y-%m-%d")
highest_date <- format(max(as.Date(departure_data$departure_scheduled_datetime_local)), "%Y-%m-%d")
```

Now I can load all the possible values for column $flight_number to collect all tweets for each flight number

```{r}
flight_numbers <- unique(departure_data$flight_number)
```

## Collect Tweets

If one were to search exclusively for flight numbers, it often happens that a large proportion of the tweets that appear in the Twitter search are not related to a flight.
Therefore, I have made some adjustments to the query in order to avoid receiving tweets that are not related to the flight on the one hand and to receive all tweets that are related to the flight on the other hand.

I have adjusted the search term so that the flight number must always be included. In order to additionally ensure that it is a tweet in connection with the flight, there must be at least one term related to the flight (terms separated by an "OR" in the prompt). I have also noticed that there are some Twitter accounts with thousands of tweets that have a username that is equal to the flight number. Tweets from these users are excluded (with "-from").

```{r}
for (flight_number in flight_numbers) {
  twitter_search_prompt <- paste0('"', flight_number, " (", 
                                  departure_data$destination_name[departure_data$flight_number == flight_number][1], 
                                  ") OR (" , departure_data$airline_name[departure_data$flight_number == flight_number][1], 
                                  ") OR (", departure_data$destination_country[departure_data$flight_number == flight_number][1],
                                  ") OR (", departure_data$destination_IATA[departure_data$flight_number == flight_number][1], 
                                  ") OR (munich) OR (MUC) OR (airport) OR (airline) OR (aircraft) OR (flight) OR (münchen) OR (flughafen) OR (flug) OR (depart) OR (departed) OR (departing) OR (departure) OR (abflug) OR (abheben) OR (abgehoben) OR (fliege) OR (fliegt) OR (jet) OR (flugzeug) OR (terminal) OR (gate) OR (flugzeit) OR (flight duration) OR (flying) OR (flying time) OR (passagier) OR (passenger) OR (delay) OR (verspätung)",
                                  " -from:@", flight_number, " since:", lowest_date,  '"')
  
  print(twitter_search_prompt)

  path_save <- paste0("../datasets/flight_tweets/tweets_", flight_number, ".json")
  command <- paste0("snscrape --jsonl --progress --max-results 10000"," twitter-search ", twitter_search_prompt, " > ", path_save)

  system(command)
}
```

## Create Dataframe with all Tweets

Snscrape inserts a json object in each line of the file for each individual tweet. No "," is inserted between the JSON-objects 
by the tool and there are no square brackets around all objects. The .json files are not yet valid, so I have to do this manually.

```{r}
convertToValidJSONString <- function(file_name) {
  file_lines <- readLines(file_name)

  # There were flight numbers for which I could not collect tweets because no tweets were posted about them. 
  if (length(file_lines) == 0) {
    return (FALSE)
  }
  
  if (length(file_lines) > 1) {
    file_lines[-length(file_lines)] <- paste0(file_lines[-length(file_lines)], ",")
  }
  
  json_string <- paste(c("[", file_lines, "]"), collapse = "")
  return(json_string)
}
```

Now I will load the .json files to compile the most important information of the tweet (username, url, date, content etc.) into a single csv file

```{r}
tweets_df <- data.frame()

for (flight_number in flight_numbers) {
  file_name <- paste0("../datasets/flight_tweets/tweets_", flight_number, ".json")
  json_string <- convertToValidJSONString(file_name)
  if (json_string != FALSE) {
     tweets <- as.data.frame(fromJSON(json_string)[c("username", "url", "date", "content", "replyCount", "retweetCount", "likeCount", "quoteCount", "lang", "bookmarkCount")])
     tweets$flight_number <- flight_number
     tweets_df <- bind_rows(tweets_df, tweets) 
  }
}

tweets_df <- tweets_df %>%
  arrange(date)

write.csv(tweets_df, file = "../datasets/flight_tweets.csv", row.names = FALSE)

head(tweets_df)
```