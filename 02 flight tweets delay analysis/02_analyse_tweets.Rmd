# Analyse Tweets

Now that some tweets have been collected, I try to identify anomalies in the dataset.

## Load Packages

```{r}
library(tidytext)
library(dplyr)
library(tidyr)
library(stringr)
library(tm)
library(SnowballC)
library(sentimentr)
```

## Load Data

```{r}
departure_data <- read.csv("../datasets/departure_dataset.csv")
flight_tweets <- read.csv("../datasets/flight_tweets.csv")
```

I decided to only consider German and English tweets, as it would be difficult to apply all the necessary pre-processing steps in all the languages that occur. Considering tweets that are German or English, a large proportion of tweets are still considered.

```{r}
print(nrow(flight_tweets[flight_tweets$lang != "en" & flight_tweets$lang != "de",]))
```

```{r}
flight_tweets <- flight_tweets[flight_tweets$lang == "en" | flight_tweets$lang == "de",]
print(nrow(flight_tweets))
head(flight_tweets)
```

## Remove Outliers

As with the data from flightera, I will remove the outliers.

```{r}
z_scores <- scale(departure_data$delay_departure_min)
z_threshold <- 3
outliers_departure_data<- abs(z_scores) > z_threshold
departure_data <- departure_data[!outliers_departure_data, ]
```

## Remove Frequent Users

Some of the tweets were written by accounts that tweet about flights in a partially automated way.

```{r}
flights_tweets_most_frequent_users <- flight_tweets %>%
  group_by(username) %>%
  summarize(count = n()) %>%
  arrange(desc(count))
head(flights_tweets_most_frequent_users, n=100)
```

Some of the tweets were written by accounts that tweet about flights in a partially automated way. 
Considering the accounts from which most of the tweets were written, I decided to exclude tweets from users who have posted at least 10 tweets.

```{r}
frequent_users <- flights_tweets_most_frequent_users %>% 
  filter(count >= 10) %>% 
  select(username)

flight_tweets <- anti_join(flight_tweets, frequent_users, by = "username")
print(nrow(flight_tweets))
head(flight_tweets)
```

## Dataset Exploration

Now let's explore the dataset. Let's take a look for which airlines the most tweets could be collected.

```{r}
flights_tweets_most_frequent_flight <- flight_tweets %>%
  group_by(flight_number) %>%
  summarize(count = n()) %>%
  arrange(desc(count))

head(flights_tweets_most_frequent_flight, n=20)
```

Calculate what the average delay is for each of the airlines

```{r}
flights_metadata <- departure_data %>%
  group_by(flight_number) %>%
  summarize(count = n(), avg_delay_min = mean(delay_departure_min)) 
head(flights_metadata)
```
## Check Correlation between Sentiment and Delay

```{r}
flight_tweets <- flight_tweets %>%
  mutate(content_cleaned = str_to_lower(content)) %>%
  mutate(content_cleaned = gsub("(https?:\\/\\/)?(www\\.)?(\\w)+(\\w|\\.|\\/)*\\.(\\w)+(\\w|\\.|\\/|\\?|\\=|\\&)*", "", content_cleaned)) %>%
  mutate(content_cleaned = removePunctuation(content_cleaned)) %>%
  mutate(content_cleaned = removeNumbers(content_cleaned)) %>%
  mutate(content_cleaned = ifelse(lang == "en", removeWords(content_cleaned, stopwords("en")), removeWords(content_cleaned, stopwords("de")))) %>%
  mutate(content_cleaned = stripWhitespace(content_cleaned)) %>%
  mutate(content_cleaned = ifelse(lang == "en", wordStem(content_cleaned, language = "english"), wordStem(content_cleaned, language = "german"))) %>%
  mutate(sentiment_score = sentiment(content_cleaned)$sentiment)

head(flight_tweets)
```

Now you can add an average delay to each tweet and the corresponding flight number.

```{r}
flight_tweets <- flight_tweets %>%
  left_join(flights_metadata, by = c("flight_number" = "flight_number"))
head(flight_tweets)
```

```{r}
plot(flight_tweets$sentiment_score, flight_tweets$avg_delay_min, xlab = "Sentiment Score", ylab = "Average Delay (minutes)", main = "Scatter Plot of Sentiment Score vs. Average Delay")
abline(lm(avg_delay_min ~ sentiment_score, data = flight_tweets), col = "red")
```

Let's calculate the Pearson correlation coefficient between the sentiment scores and average delay times. The correlation is not statistically significant (p-value = 0.8378), indicating that there is no strong linear relationship between the sentiment scores and average delay times. In conclusion, based on this analysis, there is no evidence to suggest a meaningful relationship between sentiment scores and average delay times in flight_tweets.

```{r}
# t-test for correlation coefficients
correlation_test <- cor.test(flight_tweets$sentiment_score, flight_tweets$avg_delay_min, method = "pearson")
correlation_test
```

Most frequent words

```{r}
all_tokens <- flight_tweets %>%
  unnest_tokens(word, content_cleaned)

word_frequencies <- all_tokens %>%
  count(word, sort = TRUE)

word_frequencies
```

```{r}
bigrams <- flight_tweets %>%
  unnest_tokens(bigram, content_cleaned, token = "ngrams", n = 2)

bigram_frequencies <- bigrams %>%
  count(bigram, sort = TRUE)

bigram_frequencies
```

